{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np \n",
    "import random \n",
    "import tensorflow as tf \n",
    "import matplotlib as plt\n",
    "import shutil\n",
    "from shutil import copyfile, move\n",
    "from os import getcwd \n",
    "from PIL import Image\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Data Preparation\n",
    "This part of code does the following <br>\n",
    "1. create folders to store the resize datasets <br>\n",
    "2. resize and divide the data into training and validation sets <br>\n",
    "3. resize and move the data into test set resize <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Create folder to store the resize datasets\n",
    "Each folder in training dataset consist of 42 folder represents the number of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folder for resize datasets\n",
    "m = 42 #number of class\n",
    "base_dir = getcwd()     #get the base directory\n",
    "\n",
    "#print(str(base_dir))\n",
    "train_dir_ori = os.path.join(base_dir,'datasets/train/train')\n",
    "test_dir_ori  = os.path.join(base_dir,'datasets/test/test')\n",
    "\n",
    "os.mkdir('datasets_resize')\n",
    "datasets_resize_dir = os.path.join(base_dir,'datasets_resize')\n",
    "#define the directory path\n",
    "train_dir_resize = os.path.join(datasets_resize_dir,\"train\")\n",
    "valid_dir_resize = os.path.join(datasets_resize_dir,'valid')\n",
    "test_dir_resize  = os.path.join(datasets_resize_dir,'test')\n",
    "#create the folders\n",
    "os.mkdir(train_dir_resize)\n",
    "os.mkdir(valid_dir_resize)\n",
    "os.mkdir(test_dir_resize)              \n",
    "\n",
    "for i in range(m): #loop over every folder class\n",
    "    #create class dir path\n",
    "    class_dir_val   = os.path.join(valid_dir_resize,'0'+str(i) if i<10 else str(i))       \n",
    "    class_dir_train = os.path.join(train_dir_resize,'0'+str(i) if i<10 else str(i))       \n",
    "    os.mkdir(class_dir_val)\n",
    "    os.mkdir(class_dir_train)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Resize and Split training datasets\n",
    "In order to make the data uniform in size across all the training datasets, we resize all the image to 128 x 128 pixels <br>\n",
    "and split the data into training and validation dataset with the distribution 90% and 10% respectively <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2432\n271\n2418\n269\n2432\n271\n2432\n271\n2376\n265\n2376\n265\n2394\n267\n2430\n270\n2428\n270\n2405\n268\n1658\n185\n2421\n270\n2413\n269\n2416\n269\n2368\n264\n2398\n267\n1397\n156\n1893\n211\n2411\n268\n2388\n266\n2338\n260\n2360\n263\n2286\n254\n2434\n271\n2422\n270\n2415\n269\n2431\n271\n2304\n257\n1924\n214\n2434\n271\n2409\n268\n1941\n216\n515\n58\n2339\n260\n2392\n266\n2417\n269\n1552\n173\n2405\n268\n2410\n268\n2412\n269\n2395\n267\n"
    }
   ],
   "source": [
    "#copy and resize the file from dataset train folder to datasets_resize and divide to two set (train and validation) data\n",
    "#print(os.listdir(train_dir))\n",
    "SPLIT_SIZE = 0.9\n",
    "\n",
    "for j in range(1,m):\n",
    "\n",
    "    train_source_dir = os.path.join(train_dir_ori,'0'+str(j)+'/' if j<10 else str(j)+'/')             #set the source directory\n",
    "    train_destination_dir = os.path.join(train_dir_resize,'0'+str(j)+'/' if j<10 else str(j)+'/')     #set the destination directory\n",
    "    valid_destination_dir = os.path.join(valid_dir_resize,'0'+str(j)+'/' if j<10 else str(j)+'/')\n",
    "    #print(train_source_dir)\n",
    "    \n",
    "    source_list = os.listdir(train_source_dir)                      #list all the file \n",
    "    source_list = random.sample(source_list,len(source_list))       #randomly shuffle the images\n",
    "\n",
    "    n = len(source_list)                                             #number of element in source\n",
    "    i = int(n*SPLIT_SIZE)                                            #index of valid data start\n",
    "\n",
    "    train_copy = source_list[0:i]\n",
    "    valid_copy = source_list[i:]\n",
    "\n",
    "    print(len(train_copy))\n",
    "    print(len(valid_copy))\n",
    "    \n",
    "    #loop for every images in the class folder\n",
    "    for k in train_copy:\n",
    "        #select the image\n",
    "        img_temp = Image.open(train_source_dir+k)\n",
    "        #check the image's size\n",
    "        if (img_temp.size[0] > 128) and (img_temp.size[1] > 128):\n",
    "            try:\n",
    "                #resize the image\n",
    "                img_temp.thumbnail((128,128))\n",
    "                #save image to destination\n",
    "                img_temp.save(train_destination_dir+k)\n",
    "            except OSError:\n",
    "                pass\n",
    "    \n",
    "    #loop for validation image\n",
    "    for k in valid_copy:\n",
    "        #select the image\n",
    "        img_temp = Image.open(train_source_dir+k)\n",
    "        #check the image's size\n",
    "        if (img_temp.size[0] > 128) and (img_temp.size[1] > 128):\n",
    "            try:\n",
    "                #resize the image\n",
    "                img_temp.thumbnail((128,128))\n",
    "                #save image to destination\n",
    "                img_temp.save(valid_destination_dir+k)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Resize the test datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#copy and resize the test dataset\n",
    "\n",
    "#set the source list\n",
    "source_list = os.listdir(test_dir_ori)\n",
    "n = len(source_list)\n",
    "\n",
    "for k in source_list:                                   #loop every image in the source list\n",
    "    #select the image\n",
    "    img_temp = Image.open(test_dir_ori+'/'+k)\n",
    "    #print(img_temp.size)\n",
    "    #check the image's size\n",
    "    \n",
    "    if (img_temp.size[0] > 128) and (img_temp.size[1] > 128): \n",
    "        try:\n",
    "            #resize the image\n",
    "            img_temp.thumbnail((128,128))\n",
    "            #save image to destination\n",
    "            img_temp.save(test_dir_resize+'/'+k)\n",
    "        except OSError:\n",
    "            pass\n",
    "    else: #els if the image size below 128 then just save the image\n",
    "        try:\n",
    "            #save the image to destination\n",
    "            img_temp.save(test_dir_resize+'/'+k)\n",
    "        except OSError:\n",
    "            pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit1ea465200c294a1680a2d7015494da78",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}